# **NETWORK INTRUSION DETECTION**

**Programming Language Used**: Python

**Executed on**: Hadoop Big Data Platform

**Visualization Tool Used**: Apache Zeppelin

## OVERVIEW

This learning lab can be used as a guide to get a high level understanding of Machine learning application – Network intrusion detection using logistic regression. It also describes how to use Apache Spark functions and write interactive Python code from Zeppelin. 

We will be using DevNet Data Learning Platform referred as "DLP" during the course. 

## PRE-REQUISITES

1. Install Chrome Browser.

2. Basic understanding of Apache Hadoop and Big Data.

3. Basic knowledge of Python.

4. Obtain access to Data Learning Platform -
                                                          Refer: https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/HowToAccessDTLP.md


## LEARNING OBJECTIVES

1. To get familiarized with the DLP (Data Learning Platform).

2. To get familiarized with writing and executing Python code in Zeppelin. 

3. To get familiarized with the concept of Machine Learning.

4. To get a basic understanding to build a network intrusion detector using logistic regression.

5. To get familiarized with Spark MLlib.

## TERMINOLOGIES USED

### APACHE ZEPPELIN - AN INTRODUCTION

Zeppelin is a web-based notebook that enables interactive data analytics. You can make beautiful data-driven, interactive and collaborative documents with SQL, Scala and more. 

Zeppelin enables data engineers, data analysts and data scientists to be more productive by developing, organizing, executing, and sharing data code and visualizing results without referring to the command line or knowing the cluster details. It brings data exploration, visualization, sharing and collaboration features to Spark. It supports Python and also a growing list of programming languages such as Scala, Hive, SparkSQL, shell and markdown. The various languages are supported via Zeppelin language interpreters. Zeppelin’s notebooks provides interactive snippet-at-time experience to data scientist.

###### Key Features:

1. Web based notebook style editor.

2. Built-in Apache Spark support.

###### Use Cases for Zeppelin:

1. Data Exploration and discovery

2. Data Visualization - Tables, graphs and charts

3. Interactive snippet-at-a-time experience

4. Collaboration and publishing

For more details, please refer : https://zeppelin.apache.org/


### MACHINE LEARNING - AN INTRODUCTION 

Machine learning is the subfield of computer science that gives computers the ability to learn without being explicitly programmed. It is evolved from the study of pattern recognition and computational learning theory in artificial intelligence. It is a type of Artificial Intelligence that facilitates a computer’s ability to learn and teach itself to evolve as it becomes exposed to new and ever-changing data. Machine learning is employed in a range of computing tasks where designing and programming explicit algorithms is infeasible. 


###### Machine Learning Tasks

* Classification, inputs are divided into two or more classes

* Regression, the outputs are continuous rather than discrete.

* Clustering, a set of inputs is to be divided into groups. Unlike in classification, the groups are not known beforehand, making this typically an unsupervised task.

* Density estimation finds the distribution of inputs in some space.

* Dimensionality reduction simplifies inputs by mapping them into a lower-dimensional space.


###### Examples of Machine Learning Applications 

* Network Intrusion

* Speech Recognition

* Image Recognition

* Recommender systems

* Autonomous driving etc.

For more details, please refer:
https://en.wikipedia.org/wiki/Machine_learning


## PROCESS OVERVIEW 

![alt-tag](https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/Process11.jpeg?raw=true)

Please follow the steps given below to launch the workspace and execute the program.


### **Step 1 : Select Learning Lab from DLP**

After launching the DLP dashboard page, navigate to learning labs tab. Select the learning lab "Network intrusion detection using Logistic Regression" and click on "Start" button as shown in screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection1.jpeg?raw=true)

### **Step 2 : Workspace Page**

On click of Start button, user will be navigated to a workspace page where all the components, Tools and Microservices required to execute the program are available. Please refer the screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection14.jpeg?raw=true)

### **Step 3 : Start Service in Workspace**

Points to Note:

* Start the Zeppelin service. Please refer screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection3.jpeg?raw=true)

* Once started, the colour of the icon changes to green and launch button is enabled.

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection2.jpeg?raw=true)

* If the task is in stopped status then click on it to start again. 

### **Step 4 : Launch Zeppelin**

Click on launch button and user will be navigated to Zeppelin home page.

Points to note:

(The pop-up may be blocked in browser configuration. Click on the red pop up blocker icon and select **Always allow pop-up from http://xxx.xxx.xxx.xxx ** and click on **Done** button.)  

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/popUpBlockerAllowed.PNG?raw=true)

On enabling the pop-up, Zeppelin would open in a new window taking the user to Zeppelin home page as shown in screenshot below.

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection4.jpeg?raw=true)


### **Step 5 : Select Zeppelin notebook**

* Select pre-created notebook - "Network Intrusion Detection Using Logistic Regression" from home page as shown in screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection12.jpeg?raw=true)

* The Zeppelin interactive, development and visualization environment is now ready for use. The notebook - "Network Intrusion Detection Using Logistic Regression" has all the codes required for executing this learning lab. Each of the code shown below needs to be executed sequentially. 

### **Step 6 : Execute Python Code**

We are using code written in Python to build network intrusion detector using logistic regression. 

The code is as follows:


**Download the Dataset**

```json                          
%pyspark
import urllib
print 'Start downloading dataset'                                         
training_data_url = 'http://kdd.ics.uci.edu/databases/
kddcup99/kddcup.data_10_percent.gz'  #Print 'Start downloading dataset'
urllib.urlretrieve(training_data_url, 'kddcup.data_10_percent.gz')        
print 'kddcup.data_10_percent.gz is downloaded'
testing_data_url = 'http://kdd.ics.uci.edu/databases/
kddcup99/corrected.gz'
urllib.urlretrieve(testing_data_url, 'corrected.gz')
print 'corrected.gz is downloaded'
print 'Dataset Downloaded'
```
**Uncompress the Dataset**
```json  
%pyspark
import gzip
with gzip.open('kddcup.data_10_percent.gz', 'rb') as f:
training_raw_data = f.read()
with gzip.open('corrected.gz', 'rb') as f:
testing_raw_data = f.read()
```


**Data Preparation**
```json  
%pyspark

from pyspark.mllib.regression import LabeledPoint
#Split the training and testing dataset into data records
training_data = training_raw_data.split('\n')
testing_data = testing_raw_data.split('\n')

#In order to shorten the training time, select the first 10K data from training dataset 
for training, and Select the first 1K data from testing dataset for testing
training_data_rdd = sc.parallelize(training_data[:10000])
testing_data_rdd = sc.parallelize(testing_data[:1000])

#Set the label to 0 which are "normal" connection to 0, set the label to 1 which are not 
"normal" connection
training_data_rdd_labels = training_data_rdd.map(lambda line: line.split(','))
.map(lambda line: line[:41]+[0] 
if line[41] == 'normal.' else line[:41]+[1] )
testing_data_rdd_mapped_flag = testing_data_rdd.map(lambda line: line.split(','))
.map(lambda line: line[:41]+[0] 
if line[41] == 'normal.' else line[:41]+[1] )

#Transform the records from [feature0, feature1, ..., featureN, label] to LabledPoint(label, 
[feature0, feature4, 
..., featureN]), skip the second,third and fourth feature
training_data_rdd_clean = training_data_rdd_labels.map(lambda line:LabeledPoint(line[41], 
[float(line[0])]+[float(i) 
for i in line[4:41]]))

#Transform the records from [feature0, feature1, ..., featureN, label] to [feature0, 
feature4, ..., featureN], 
skip the second, third and fourth feature
testing_data_rdd_clean = testing_data_rdd_mapped_flag.map(lambda line:[float(line[0])]+[float(i) for i 
in line[4:41]])

#Extract the labels of testing dataset
testing_data_rdd_labels = testing_data_rdd_mapped_flag.map(lambda line:line[41])
```
**Select the algorithm**

```json 
%pyspark

#You can use different algorithms to train the model, they are Naive Bayes, Logistic Regression, SVM
value = z.select("Please select the Machine Learning algorithm:", [("1", "Naive Bayes"), ("2", "Logistic Regression"), ("3", "SVM")], "1")
```

**Train the Logistic Regression Model**
```json  
%pyspark
model = None
if value == "1":
    from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel
    model = NaiveBayes.train(training_data_rdd_clean, 1.0)
elif value == "2":
    from pyspark.mllib.classification import LogisticRegressionWithSGD, LogisticRegressionModel
    model = LogisticRegressionWithSGD.train(training_data_rdd_clean, iterations=100)
else:
    from pyspark.mllib.classification import SVMWithSGD, SVMModel
    model = SVMWithSGD.train(training_data_rdd_clean, iterations=100)
```

**Evaluate the performance of Logistic Regression Model**
```json  
%pyspark
prediction = lrm.predict(testing_data_rdd_clean)
prediction_true_pair = zip(prediction.collect(), testing_data_rdd_labels.collect())
accuracy = sc.parallelize(prediction_true_pair).filter(lambda (p, t): p == t).count() / (float)(testing_data_rdd_labels.count())
print 'Classification Accuracy: %f' % accuracy
```

**Following functions are being done by the Python Code :**

1. Download the KDD 99 dataset for training data and testing data from internet

2. Uncompress KDD 99 dataset

3. Data Preparation

   Split the training and testing dataset into data records.
   
   In order to shorten the training time, select the first 10K data from training dataset for training, and 
   select the first 1K data from testing dataset for testing.
   
   Set the label to 0 which are "normal" connection to 0, set the label to 1 which are not "normal" connection.
   
   Remove 2,3,4 features in training data and testing data.
   
   Extract the labels of testing dataset.
   
4. Select the algorithm - the options available are Naive Bayes, Logistic Regression or SVM.
   
5. Train the model using the selected algorithm in previous step.

6. Evaluate the performance of the Model.

Execute the codes by clicking on the "Ready" icon highlighted as shown in screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection7.jpeg?raw=true)

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection8.jpeg?raw=true)

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection9.jpeg?raw=true)

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection10.jpeg?raw=true)

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection11.jpeg?raw=true)

On successful execution of code, you can see the icon getting changed to "FINISHED" as shown in screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection13.jpeg?raw=true)

### **Step 7 : View Classification Accuracy**

The logistic Regression Model shows a Classification Accuracy : 0.869000 as shown in screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/NETWORK%20INTRUSION%20DETECTION%20USING%20LOGISTIC%20REGRESSION/assets/images/NetworkDetection15.jpeg?raw=true)


## LESSONS LEARNT

1. How to write and execute Python code in Zeppelin.

2. How to build a Network intrusion detector using Logistic Regression.


# **Congratulations! You have successfully completed the Learning Lab!**
