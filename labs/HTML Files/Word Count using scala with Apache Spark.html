<!DOCTYPE html><html><head><meta charset="utf-8"><title>Untitled Document.md</title><style></style></head><body id="preview">
<h1><a id="WORD_COUNT_USING_SCALA_WITH_APACHE_SPARK_0"></a>WORD COUNT USING SCALA WITH APACHE SPARK</h1>
<p><strong>Processing Engine Used</strong>: Apache Spark</p>
<p><strong>Programming Language Used</strong>: Scala</p>
<p><strong>Executed on</strong>: Hadoop Big Data Platform</p>
<h2><a id="OVERVIEW_8"></a>OVERVIEW</h2>
<p>This learning lab can be used as a guide to get a high level understanding of Apache Spark with Scala programming language. It describes how to write, compile, and run a simple Spark word count application in Scala programming language. We will be using DevNet Data Learning Platform referred as “DLP” during the course.</p>
<h2><a id="PREREQUISITES_12"></a>PRE-REQUISITES</h2>
<ol>
<li>
<p>Install Chrome Browser.</p>
</li>
<li>
<p>Basic understanding of Apache Hadoop and Big Data.</p>
</li>
<li>
<p>Obtain access to Data Learning Platform -<br>
Refer: <a href="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/HowToAccessDTLP.md">https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/HowToAccessDTLP.md</a></p>
</li>
</ol>
<h2><a id="LEARNING_OBJECTIVES_21"></a>LEARNING OBJECTIVES</h2>
<ol>
<li>
<p>To get familiarized with the DLP (Data Learning Platform)</p>
</li>
<li>
<p>To get familiarized with Scala programming.</p>
</li>
<li>
<p>To get familiarized with the RDD operations on data using spark.</p>
</li>
</ol>
<h2><a id="TERMINOLOGIES_USED_29"></a>TERMINOLOGIES USED</h2>
<h3><a id="APACHE_SPARK__AN_INTRODUCTION_31"></a>APACHE SPARK - AN INTRODUCTION</h3>
<p>Apache Spark is an open source cluster computing framework. Spark is advertised as “lightning fast cluster computing”. It has a thriving open-source community and is the most active Apache project at the moment. Spark provides an interface for programming entire clusters with implicit data parallelism and fault-tolerance. Apache Spark provides programmers with an application programming interface centered on a data structure called the resilient distributed dataset (RDD), a read-only multiset of data items distributed over a cluster of machines, that is maintained in a fault-tolerant way.</p>
<p>It was developed in response to limitations in the MapReduce cluster computing paradigm, which forces a particular linear dataflow structure on distributed programs. MapReduce programs read input data from disk, map a function across the data, reduce the results of the map, and store reduction results on disk. Spark provides a faster and more general data processing platform.</p>
<h6><a id="Key_Features_37"></a>Key Features</h6>
<ol>
<li>Currently provides APIs in Scala, Java, and Python, with support for other languages (such as R) on the way</li>
<li>Integrates well with the Hadoop ecosystem and data sources (HDFS, Amazon S3, Hive, HBase, Cassandra, etc.)</li>
<li>Can run on clusters managed by Hadoop YARN or Apache Mesos, and can also run standalone</li>
</ol>
<h6><a id="How_to_Use_Apache_Spark_43"></a>How to Use Apache Spark?</h6>
<h6><a id="Example__Using_spark_to_detect_an_earthquake_by_analyzing_the_twitter_stream_45"></a>Example : Using spark to detect an earthquake by analyzing the twitter stream</h6>
<ol>
<li>
<p>Using Spark streaming, filter tweets that seem relevant like “earthquake” or “shaking”.</p>
</li>
<li>
<p>Run semantic analysis on the tweets to determine if they appear to be referencing a current earthquake occurrence. Tweets like ”Earthquake!” or ”Now it is shaking”, for example, would be considered positive matches, whereas tweets like “Attending an Earthquake Conference” or ”The earthquake yesterday was scary” would not.</p>
</li>
<li>
<p>Using the streaming technique we could detect positive tweets in a defined time window and thereby can be used to send alert messages.</p>
</li>
</ol>
<p>For more details, please refer:<br>
<a href="http://spark.apache.org/">http://spark.apache.org/</a><br>
<a href="https://en.wikipedia.org/wiki/Apache_Spark">https://en.wikipedia.org/wiki/Apache_Spark</a></p>
<h3><a id="SCALA__AN_INTRODUCTION_58"></a>SCALA - AN INTRODUCTION</h3>
<p>Scala is an acronym for “Scalable Language”. This means that Scala grows with you. Scala could be written by typing one-line expressions and observing the results and  could also be used for large mission critical systems. Scala could also be considered as a scripting language and is a pure-bred object-oriented language. The language supports advanced component architectures through classes and traits. Even though its syntax is fairly conventional, Scala is also a full-blown functional language. Scala runs on the JVM. Java and Scala classes can be freely mixed, no matter whether they reside in different projects or in the same. Scala makes deliver things faster with less code.</p>
<p>For more details, please refer:<br>
<a href="http://www.scala-lang.org/what-is-scala.html">http://www.scala-lang.org/what-is-scala.html</a><br>
<a href="https://en.wikipedia.org/wiki/Scala_(programming_language)">https://en.wikipedia.org/wiki/Scala_(programming_language)</a></p>
<h3><a id="HADOOP__AN_INTRODUCTION_67"></a>HADOOP - AN INTRODUCTION</h3>
<p>Apache Hadoop is an open-source software framework for distributed storage and distributed processing of very large data sets on computer clusters built from commodity hardware. To understand Hadoop, there are two fundamental things about it -  How Hadoop stores files and how it processes data. The framework that is used in Hadoop to process data is called MapReduce.</p>
<p>All the modules in Hadoop are designed with a fundamental assumption that hardware failures are common and should be automatically handled by the framework. The core of Apache Hadoop consists of a storage part, known as Hadoop Distributed File System (HDFS), and a processing part called MapReduce. Hadoop splits files into large blocks and distributes them across nodes in a cluster.</p>
<p>Example : Imagine a file that is larger than the capacity of a computer then it would not be possible to store that file. Hadoop allows to store files bigger than what can be stored on one particular node or server. So it provides an ability to store very, very large files and also lets to store many, many files.</p>
<p>For more details, please refer:<br>
(<a href="https://en.wikipedia.org/wiki/Apache_Hadoop">https://en.wikipedia.org/wiki/Apache_Hadoop</a>)</p>
<h3><a id="USE_CASE_78"></a>USE CASE</h3>
<p>WordCount is used as an example here to demonstrate the use of Scala programming language using Apache Spark on Hadoop. The purpose of this program is to count how many times a word occurs in a text using RDD. The scala program used does the following:</p>
<ol>
<li>Create a <a href="http://spark.apache.org/docs/1.5.0/api/scala/index.html#org.apache.spark.SparkContext">SparkContext</a>.</li>
<li>Load input data from a file.</li>
<li>Read an input set of text and split the data in to words.</li>
<li>Counts the number of times each word appears and transform it in to word and count.</li>
<li>Save the word count output back to a text file.</li>
</ol>
<h2><a id="PROCESS_OVERVIEW_88"></a>PROCESS OVERVIEW</h2>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/Process1.jpeg?raw=true" alt="alt-tag"></p>
<p>Please follow the steps given below to launch the workspace and execute the lab.</p>
<h3><a id="Step_1__Select_Learning_Lab_from_DLP_94"></a><strong>Step 1 : Select Learning Lab from DLP</strong></h3>
<p>After launching the DLP dashboard page, navigate to learning labs tab. Select the learning lab “Word Count Using Scala Programming with Apache Spark” and click on “Start” button as shown in screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/DevNetLanding1.jpeg?raw=true" alt="alt-tag"></p>
<p>P.S: This learning lab can also be selected from the home page.</p>
<h3><a id="Step_2__Navigate_to_Workspace_Page_102"></a><strong>Step 2 : Navigate to Workspace Page</strong></h3>
<p>On click of Start button, you will be navigated to a workspace page where all the components - IDE, Tools and Microservices required to execute the program are available. Please refer the screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/DevNetWrkSpcTask2.jpeg?raw=true" alt="alt-tag"></p>
<h3><a id="Step_3__Tasks_in_Workspace_108"></a><strong>Step 3 : Tasks in Workspace</strong></h3>
<p>Points to Note:</p>
<ul>
<li>Start the task in Cloud IDE(where eclipse icon is shown). Please refer screenshot below:</li>
</ul>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/DevNetWrkSpcTask3.jpeg?raw=true" alt="alt-tag"></p>
<p>Once started, the colour of the icon changes to green as shown below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/DevNetWrkSpcTask.jpeg?raw=true" alt="alt-tag"></p>
<ul>
<li>
<p>If the task is in stopped status then click on it to start again.</p>
</li>
<li>
<p>Click launch in cloud IDE pane (where eclipse icon is shown) and you will be navigated to a pre-configured IDE (Integrated Development Environment) as shown in the screenshot below:</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/IDE%20workspace%201.jpeg?raw=true" alt="alt-tag"></p>
<ul>
<li>Click on the left menu tree - word count folder under project explorer. The folder will expand and show all the files underneath. The folder structure is as shown in screenshot below:</li>
</ul>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/IDE%20workspace%203.jpeg?raw=true" alt="alt-tag"></p>
<p>Note: The file names mentioned below are used in this learning lab.</p>
<ol>
<li>WordCount.scala</li>
<li><a href="http://WordCountRun.sh">WordCountRun.sh</a></li>
<li>word_count_input_file.txt</li>
<li><a href="http://view.sh">view.sh</a></li>
</ol>
<h3><a id="Step_4__Scala_Program_on_IDE_139"></a><strong>Step 4 : Scala Program on IDE</strong></h3>
<p>Select the file “WordCount.scala” from left pane on IDE work space. The below mentioned code snippet would be shown:</p>
<pre><code class="language-json">//Import libraries which are needed to run the program. 
import org.apache.spark.{SparkContext, SparkConf}
object WordCount
{
  def main(args: Array[String]) {
    val inputFile = args(0)
    val outputFile = args(1)
    val conf = new SparkConf().setAppName("wordCount")
    // Create a Scala Spark Context.
    val sc = new SparkContext(conf)
    // Load our input data.
    val input = sc.textFile(inputFile)
    // Split up into words.
    val words = input.flatMap(line =&gt; line.split(" "))
    // Transform into word and count.
    val counts = words.map(word =&gt; (word, 1)).reduceByKey{_ + _}
    // Save the word count back out to a text file, causing evaluation.
    counts.saveAsTextFile(outputFile)
  }
}
</code></pre>
<p>Note: The code does the following:</p>
<ol>
<li>A Spark context is created</li>
<li>Input file : “word_count_input_file.txt” which is passed as a parameter is read.</li>
<li>The data is split in to words (identified using a single space “ “)</li>
<li>The number of times each word appears is counted and transformed in to word / count.</li>
<li>The word and count output is saved back and written to the IDE console.</li>
</ol>
<h3><a id="Step_5__Modify_Input_file_175"></a><strong>Step 5 : Modify Input file</strong></h3>
<p>Select the input file “word_count_input_file.txt” from IDE workspace and modify as required.</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/EditInputFile.png" alt="alt-tag"></p>
<p>Note: This file would be passed as input to the scala code – “WordCount.scala”.</p>
<p>In order to execute the scala program and view the output the following steps would need to be done :</p>
<ol>
<li>Build and package the scala program.</li>
<li>Run the scala program</li>
<li>View the output</li>
</ol>
<h3><a id="Step_6___Package_the_program_188"></a><strong>Step 6 :  Package the program</strong></h3>
<p>Select the file – “WordCount.scala” from the left pane and on the top pane select CMD as “Package” and click on blue icon (<img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/icon.jpeg?raw=true" alt="alt-tag">) as shown in the screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/Package.jpeg?raw=true" alt="alt-tag"></p>
<p>Note : This will help to build and package the scala program.</p>
<h3><a id="Step_7__Successful_Build_Completion_197"></a><strong>Step 7 : Successful Build Completion</strong></h3>
<p>Check the console as shown below for a successful completion message:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/Preview_snapshot.jpeg?raw=true" alt="alt-tag"></p>
<h3><a id="Step_8__Run_the_program_203"></a><strong>Step 8 : Run the program</strong></h3>
<p>Select the CMD as “run” and click on blue icon(<img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/icon.jpeg?raw=true" alt="alt-tag">) as shown in the screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/Run.jpeg?raw=true" alt="alt-tag"></p>
<h3><a id="Step_9__Successful_Run_Command_Execution_209"></a><strong>Step 9 : Successful Run Command Execution</strong></h3>
<p>Check the console as shown below for a successful completion message:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/Run_1.jpeg?raw=true" alt="alt-tag"></p>
<h3><a id="Step_10__View_the_results_215"></a><strong>Step 10 : View the results</strong></h3>
<p>Select the CMD as “view” and click on blue icon(<img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/icon.jpeg?raw=true" alt="alt-tag">) as shown in the screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/View_latest.jpeg?raw=true" alt="alt-tag"></p>
<h3><a id="Step_11__Check_output_on_IDE_console_221"></a><strong>Step 11 : Check output on IDE console</strong></h3>
<p>Check the console for the program output. The output would be shown as below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/View_console.jpeg?raw=true" alt="alt-tag"></p>
<p>Note: <a href="http://view.sh">view.sh</a> file is used to pick the file from Hadoop environment and show the output in IDE’s output console.</p>
<p>On completing this exercise, we have learned how to count the number of words in an input file using Spark Batch Processing.</p>
<table class="table table-striped table-bordered">
<thead>
<tr>
<th>Input</th>
<th>Output</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hello spark I love Cisco Company. Hello all. We are practicing Word Count Program using Scala and Spark.</td>
<td>(are,1), (Program,1),(Hello,2),(love,1),(Word,1),(practicing,1),(using,1),(We,1),(Scala,1),(Cisco.,1),(spark,1),(Count,1),(I,1),(All,1),(Company.,1),(Spark.,1),(Cisco,1),(and,1),(all.,1)</td>
</tr>
</tbody>
</table>
<p>Step 9 : Stop Eclipse service</p>
<p>After viewing the output from IDE console, we need to stop the Eclipse service from DLP.</p>
<p>Please refer screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/DevNetWrkSpcTask6.jpeg?raw=true" alt="alt-tag"></p>
<h2><a id="LESSONS_LEARNT_243"></a>LESSONS LEARNT:</h2>
<ol>
<li>
<p>A high level understanding of Apache Spark.</p>
</li>
<li>
<p>How to write, compile and run a basic Scala program.</p>
</li>
<li>
<p>How to do RDD operations on data using Apache Spark.</p>
</li>
</ol>
<h2><a id="Congratulations_You_have_successfully_completed_the_Learning_Lab_251"></a><strong>Congratulations! You have successfully completed the Learning Lab!</strong></h2>

</body></html>