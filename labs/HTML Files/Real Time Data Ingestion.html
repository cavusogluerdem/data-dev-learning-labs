<!DOCTYPE html><html><head><meta charset="utf-8"><title>Untitled Document.md</title><style></style></head><body id="preview">
<h1><a id="REAL_TIME_DATA_INGESTION_0"></a>REAL TIME DATA INGESTION</h1>
<p><strong>Stream Processing Platform Used</strong>: Apache Kafka</p>
<p><strong>Executed on</strong>: Hadoop Big Data Platform</p>
<h2><a id="OVERVIEW_7"></a>OVERVIEW</h2>
<p>This learning lab can be used as a guide to get a high level understanding on the process of ingesting data real time from different data sources like MQTT, Kafka and Twitter to HDFS using Apache Nifi in to Hadoop environment.</p>
<p>We will be using DevNet Data Learning Platform referred as “DLP” during the course.</p>
<h2><a id="PREREQUISITES_13"></a>PRE-REQUISITES</h2>
<ol>
<li>
<p>Install Chrome Browser.</p>
</li>
<li>
<p>Basic Knowledge of data storage on Hadoop.</p>
</li>
<li>
<p>Basic knowledge of Apache Kafka.</p>
</li>
<li>
<p>Obtain access to Data Learning Platform -<br>
Refer: <a href="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/HowToAccessDTLP.md">https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/HowToAccessDTLP.md</a></p>
</li>
</ol>
<h2><a id="LEARNING_OBJECTIVES_25"></a>LEARNING OBJECTIVES</h2>
<ol>
<li>
<p>To get familiarized with the DLP (Data Learning Platform).</p>
</li>
<li>
<p>To get familiarized with the ways to ingest real time data from different data sources like MQTT, Kafka and Twitter to HDFS    using Apache Nifi.</p>
</li>
<li>
<p>To get familiarized with the ways to get network data from HDFS.</p>
</li>
<li>
<p>To get familiarized with ways to visualize data from DLP platform.</p>
</li>
</ol>
<h2><a id="TERMINOLOGIES_USED_36"></a>TERMINOLOGIES USED</h2>
<h3><a id="WHAT_IS_NETWORK_DATA_39"></a>WHAT IS NETWORK DATA?</h3>
<p>The Computer network is a telecommunication process which allows computers or devices to exchange data between each other using data pipeline and those devices that are controlled by wired or wireless medium. Those devices are kept alive by exchanging data between each other in a continuous way.</p>
<p>These network data provide the inside details about communication performance between of two devices that are communicating. We can extract lots of valuable information from those data set if we can capture those data in real time.</p>
<h2><a id="APACHE_NIFI__AN_INTRODUCTION_45"></a>APACHE NIFI - AN INTRODUCTION</h2>
<p>NiFi was built to automate the flow of data between systems. The termÿdataflowÿhere refers to automated and managed flow of information between systems. Some of the high-level challenges of dataflow include:</p>
<ol>
<li>Systems fail : Networks fail, disks fail, software crashes, people make mistakes.</li>
<li>Data access exceeds capacity to consume : Sometimes a given data source can outpace some part of the processing or delivery chain - it only takes one weak-link to have an issue.</li>
<li>Boundary conditions are mere suggestions : You will invariably get data that is too big, too small, too fast, too slow, corrupt, wrong, or in the wrong format.</li>
<li>What is noise one day becomes signal the next : Priorities of an organization change - rapidly. Enabling new flows and changing existing ones must be fast.</li>
<li>Systems evolve at different rates : The protocols and formats used by a given system can change anytime and often irrespective of the systems around them. Dataflow exists to connect what is essentially a massively distributed system of components that are loosely or not-at-all designed to work together.</li>
<li>Compliance and security : Laws, regulations, and policies change. Business to business agreements change. System to system and system to user interactions must be secure, trusted, accountable.</li>
<li>Continuous improvement occurs in production : It is often not possible to come even close to replicating production environments in the lab.</li>
</ol>
<p>NiFi is built to help tackle these modern dataflow challenges.</p>
<p>For more details, please refer:<br>
<a href="http://nifi.apache.org/docs/nifi-docs/html/overview.html">http://nifi.apache.org/docs/nifi-docs/html/overview.html</a></p>
<h2><a id="APACHE_KAFKA__AN_INTRODUCTION_61"></a>APACHE KAFKA - AN INTRODUCTION</h2>
<p>Kafka is a distributed streaming platform that is designed to be fast, scalable, and durable. It has 3 key capabilities:</p>
<ol>
<li>It lets you publish and subscribe to streams of records. In this respect,    it is similar to a message queue or enterprise messaging system.</li>
<li>It lets you store streams of records in a fault-tolerant way.</li>
<li>It lets you process streams of records as they occur.</li>
</ol>
<p>It is used for two broad classes of application:</p>
<ol>
<li>Building real-time streaming data pipelines that reliably get data between systems or applications</li>
<li>Building real-time streaming applications that transform or react to the streams of data</li>
</ol>
<p>For more details, please refer:<br>
<a href="https://kafka.apache.org/">https://kafka.apache.org/</a></p>
<h2><a id="PROCESS_OVERVIEW_78"></a>PROCESS OVERVIEW</h2>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/Process14.jpeg?raw=true" alt="alt-tag"></p>
<p>Please follow the steps given below to launch the workspace and execute the lab.</p>
<h3><a id="Step_1__Select_Learning_lab_from_DLP_84"></a><strong>Step 1 : Select Learning lab from DLP</strong></h3>
<p>After launching the DLP dashboard page, navigate to learning labs tab. Select the learning lab “Real Time Data Ingestion” and click on “Start” button as shown in screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/REAL%20TIME%20DATA%20INGESTION/assets/images/RTDI1.jpeg?raw=true" alt="alt-tag"></p>
<h3><a id="Step_2__Workspace_Page_91"></a><strong>Step 2 : Workspace Page</strong></h3>
<p>On click of Start button, user will be navigated to a workspace page where all the components - IDE, Tools and Microservices required to execute the program are available. Please refer the screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/REAL%20TIME%20DATA%20INGESTION/assets/images/RTDI2.jpeg?raw=true" alt="alt-tag"></p>
<h3><a id="Step_3__Input_and_Output_Configuration_97"></a><strong>Step 3 : Input and Output Configuration</strong></h3>
<p>Click on the configuration settings button provided in “Tools and Microservices” column. Please refer screenshot below. The input and output configuration existing for the learning lab is shown.</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/REAL%20TIME%20DATA%20INGESTION/assets/images/RTDI4.jpeg?raw=true" alt="alt-tag"></p>
<h3><a id="Step_4__Start_Tasks_in_workspace_103"></a><strong>Step 4 : Start Tasks in workspace</strong></h3>
<p>Points to Note:</p>
<ul>
<li>Start the tasks in “Tools and Microservices” column. Please refer screenshot below:</li>
</ul>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/REAL%20TIME%20DATA%20INGESTION/assets/images/RTDI3.jpeg?raw=true" alt="alt-tag"></p>
<ul>
<li>Once started, the colour of the icon changes to green as shown in screen below:</li>
</ul>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/REAL%20TIME%20DATA%20INGESTION/assets/images/RTDI5.jpeg?raw=true" alt="alt-tag"></p>
<ul>
<li>If the task is in stopped status then click on it to start again.</li>
</ul>
<p>Data source section will get real-time traffic from traffic server and feed to Kafka cluster. EasyNifi allows to save the real-time data to HDFS. From HDFS, we can visualize the data using visualization tools like Tableau.</p>
<p>The generated output file is shown in section - “File List”</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/REAL%20TIME%20DATA%20INGESTION/assets/images/RTDI6.jpeg?raw=true" alt="alt-tag"></p>
<p>Click on the button with an eye symbol to view the network data as shown in screenshot below.</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/REAL%20TIME%20DATA%20INGESTION/assets/images/RTDI7.jpeg?raw=true" alt="alt-tag"></p>
<p>PS: The window needs to be refreshed if the output file is not seen.<br>
&lt;/br&gt;</p>
<h3><a id="Step_5__Stop_Tasks_in_workspace_131"></a><strong>Step 5 : Stop Tasks in workspace</strong></h3>
<p>After viewing the network data, stop the task by clicking on <strong>Stop</strong> button in “Tools and Microservices” column. Please refer screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/REAL%20TIME%20DATA%20INGESTION/assets/images/RTDI5.jpeg?raw=true" alt="alt-tag"></p>
<h2><a id="LESSONS_LEARNT_137"></a>LESSONS LEARNT:</h2>
<ol>
<li>
<p>How to ingest real time data from different data sources like MQTT, Kafka and Twitter to HDFS using Apache Nifi.</p>
</li>
<li>
<p>How to get network data from HDFS.</p>
</li>
<li>
<p>How to visualize data from HDFS via DLP platform.</p>
</li>
</ol>
<h1><a id="Congratulations_You_have_successfully_completed_the_Learning_Lab_145"></a><strong>Congratulations! You have successfully completed the Learning Lab!</strong></h1>

</body></html>