<!DOCTYPE html><html><head><meta charset="utf-8"><title>Untitled Document.md</title><style></style></head><body id="preview">
<h1><a id="HADOOP_101_WITH_BASIC_TERMINAL_HANDSON_EXERCISES_1"></a><strong>HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES</strong></h1>
<p><strong>Executed on</strong> : Hadoop Terminal</p>
<h2><a id="OVERVIEW_5"></a>OVERVIEW</h2>
<p>This learning lab can be used as a guide to get a high level understanding of Apache Hadoop. The prime focus would be to,</p>
<ol>
<li>
<p>Get a basic understanding of Hadoop infrastructure.</p>
</li>
<li>
<p>Learn how to execute HDFS command.</p>
</li>
<li>
<p>Learn how to use Apache Spark-shell to interact with Spark cluster.</p>
</li>
<li>
<p>Learn how to use Hive command to interact with Hive cluster</p>
</li>
</ol>
<p>We will be using DevNet Data Learning Platform referred as “DLP” during the course.</p>
<h2><a id="PREREQUISITES_19"></a>PRE-REQUISITES</h2>
<ol>
<li>
<p>Install Chrome Browser.</p>
</li>
<li>
<p>User should have a basic exposure to Core Java, database concepts and any of the Linux operating system flavors.</p>
</li>
<li>
<p>Obtain access to Data Learning Platform -<br>
Refer: <a href="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/HowToAccessDTLP.md">https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/HowToAccessDTLP.md</a></p>
</li>
</ol>
<h2><a id="LEARNING_OBJECTIVES_28"></a>LEARNING OBJECTIVES</h2>
<ol>
<li>
<p>To get familiarized with the DLP (Data Learning Platform)</p>
</li>
<li>
<p>To get familiarized with Apache Hadoop.</p>
</li>
<li>
<p>To get familiarized with the terminal usage for executing HDFS commands.</p>
</li>
</ol>
<h2><a id="TERMINOLOGIES_USED_36"></a>TERMINOLOGIES USED</h2>
<h3><a id="HADOOP__AN_INTRODUCTION_38"></a>HADOOP - AN INTRODUCTION</h3>
<p>What is Hadoop?</p>
<p>Hadoop is an open-source framework that allows to store and process big data in a distributed environment across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Hadoop splits files into large blocks and distributes them across nodes in a cluster. All the modules in Hadoop are designed with a fundamental assumption that hardware failures are common and should be automatically handled by the framework.</p>
<p>There are two fundamental things about Hadoop :</p>
<ol>
<li>File Storage (known as Hadoop Distributed File System (HDFS)</li>
<li>Data Processing (known as MapReduce)</li>
</ol>
<p><strong>Hadoop Evolution Overview</strong></p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/Hadoop.jpeg?raw=true" alt="alt-tag"></p>
<p><strong>Hadoop Architecture</strong></p>
<p>&lt;img src=&quot;<a href="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/Hadoop">https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP 101 WITH BASIC TERMINAL HANDS-ON EXERCISES/assets/images/Hadoop</a> Architecture.jpeg?raw=true&quot; data-canonical-src=&quot;<a href="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/HOW">https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/HOW</a> TO EXECUTE BASIC COMMAND IN HADOOP TERMINAL/assets/images/Hadoop Architecture.jpeg?raw=true&quot; width=“600” height=“300” /&gt;</p>
<p>Hadoop framework includes following four modules:</p>
<ol>
<li>
<p><strong>Hadoop Common:</strong> These are Java libraries and utilities required by other Hadoop modules. These libraries provides filesystem and OS level abstractions and contains the necessary Java files and scripts required to start Hadoop.</p>
</li>
<li>
<p><strong>Hadoop YARN:</strong> A framework for job scheduling and cluster resource management.</p>
</li>
<li>
<p><strong>Hadoop Distributed File System (HDFS™):</strong> A distributed file system that provides high-throughput access to application data.</p>
</li>
<li>
<p><strong>Hadoop MapReduce:</strong> A YARN-based system for parallel processing of large data sets.</p>
</li>
</ol>
<p>For more details, please refer:</p>
<p><a href="https://en.wikipedia.org/wiki/Apache_Hadoop">https://en.wikipedia.org/wiki/Apache_Hadoop</a></p>
<p><a href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p>
<h2><a id="PROCESS_OVERVIEW_73"></a>PROCESS OVERVIEW</h2>
<p>In this learning lab, we will focus on three different exercises which are as follows:</p>
<ol>
<li>
<p>How to execute HDFS command.</p>
</li>
<li>
<p>How to use Apache Spark-shell to interact with Spark cluster.</p>
</li>
<li>
<p>How to use Hive command to interact with Hive cluster</p>
</li>
</ol>
<h3><a id="HOW_TO_EXECUTE_BASIC_HDFS_COMMAND_84"></a>HOW TO EXECUTE BASIC HDFS COMMAND</h3>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/Process10.jpeg?raw=true" alt="alt-tag"></p>
<p>Please follow the steps given below to launch the workspace and execute the program.</p>
<h3><a id="Step_1__Select_Learning_Lab_from_DLP_90"></a><strong>Step 1 : Select Learning Lab from DLP</strong></h3>
<p>After launching the DLP dashboard page, navigate to learning labs tab. Select the learning lab “Hadoop 101 with basic terminal hands-on exercises” and click on “Start” button as shown in screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic.jpeg?raw=true" alt="alt-tag"></p>
<h3><a id="Step_2__Workspace_Page_96"></a><strong>Step 2 : Workspace Page</strong></h3>
<p>On click of Start button, you will be navigated to a workspace page where all the components - IDE, Tools and Microservices required to execute the program are made available. Please refer the screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic2.png?raw=true" alt="alt-tag"></p>
<h3><a id="Step_3__Tasks_in_Workspace_102"></a><strong>Step 3 : Tasks in Workspace</strong></h3>
<p>Points to Note:</p>
<p>The following files will be used in this learning lab which are made available in workspace (DataSource - File):</p>
<ol>
<li>hadoop-learning-labs-demo.txt</li>
<li>hadoop-learning-labs-people.json</li>
<li>hadoop-learning-labs-people.txt</li>
<li>hive_students.csv</li>
</ol>
<ul>
<li>Start terminal service. Please refer screenshot below:</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic3.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Once started, the colour of the icon changes to green and launch button is enabled as shown in screenshot below:</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic4.png?raw=true" alt="alt-tag"></p>
<ul>
<li>If the task is in stopped status then click on it to start again.</li>
</ul>
<h3><a id="Step_4__Launch_Hadoop_Terminal_123"></a><strong>Step 4 : Launch Hadoop Terminal</strong></h3>
<p>On click of launch button, you will be navigated to hadoop terminal which would open in a separate tab as shown in screenshot below:</p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic5.png?raw=true" alt="alt-tag"></p>
<p>Provide login id and password on the terminal prompt as shown in screenshot below: (<strong>Login ID</strong> : root / <strong>Password</strong> : cisco)</p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic10.png?raw=true" alt="alt-tag"></p>
<h3><a id="Step_5__Execute_Basic_Commands_135"></a><strong>Step 5 : Execute Basic Commands</strong></h3>
<p>Execute some of the basic commands in hadoop terminal.</p>
<p>Please find each command snippet with the output. Copy paste each of the commands given below to the terminal and view the output obtained.</p>
<p><strong>Create a directory in HDFS:</strong></p>
<pre><code class="language-jason">hdfs dfs -mkdir ${HDFS}learning-labs/
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic11.png?raw=true" alt="alt-tag"></p>
<p>To view output:</p>
<pre><code class="language-jason">hdfs dfs -ls ${HDFS}
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic12.png?raw=true" alt="alt-tag"></p>
<p>Please Note:<br>
HDFS – Environment Parameter<br>
Learning-labs – directory name</p>
<p><strong>File upload to HDFS from local desktop:</strong></p>
<ul>
<li>Create a file in the local system with the content as hello, hadoop-learning-labs. Please follow the command mentioned below to do so:</li>
</ul>
<pre><code class="language-jason">echo “hello, hadoop-learning-labs” &gt;&gt; hadoop-learning-labs.txt
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic13.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Upload file via -put or -copyFromLocal command from local file to HDFS.</li>
</ul>
<pre><code class="language-jason">hdfs dfs –put hadoop-learning-labs.txt ${HDFS}learning-labs/
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic15.png?raw=true" alt="alt-tag"></p>
<ul>
<li>View the uploaded file as follows:</li>
</ul>
<pre><code class="language-jason">hdfs dfs –ls ${HDFS}learning-labs/
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic17.png?raw=true" alt="alt-tag"></p>
<h3><a id="Step_6__File_download_from_HDFS_to_local_desktop_185"></a><strong>Step 6 : File download from HDFS to local desktop</strong></h3>
<p>P.S: if hadoop-learning-labs.txt file exists in local directory then it needs to be deleted first.</p>
<ul>
<li>Remove file - “hadoop-learning-labs.txt” from local directory if it exists.</li>
</ul>
<pre><code class="language-jason">rm hadoop-learning-labs.txt
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic18.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Get the file from HDFS to local directory using -get command</li>
</ul>
<pre><code class="language-jason">hdfs dfs –get ${HDFS}learning-labs/hadoop-learning-labs.txt
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic19.png?raw=true" alt="alt-tag"></p>
<p>To view output:</p>
<pre><code class="language-jason">ls –lh hadoop-learning-labs.txt 
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic20.png?raw=true" alt="alt-tag"></p>
<h3><a id="Step_7__List_Files_or_View_File_Content_in_HDFS_directory_212"></a><strong>Step 7 : List Files or View File Content in HDFS directory.</strong></h3>
<ul>
<li>List the files in HDFS directory:</li>
</ul>
<pre><code class="language-jason">hdfs dfs –ls ${HDFS}learning-labs/
</code></pre>
<p>Output of the command is as shown below:<br>
<img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic23.png?raw=true" alt="alt-tag"></p>
<ol start="2">
<li>View the contents of the file “hadoop-learning-labs.txt” present in HDFS directory:</li>
</ol>
<pre><code class="language-jason">hdfs dfs –cat ${HDFS}learning-labs/hadoop-learning-labs.txt
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic22.png?raw=true" alt="alt-tag"></p>
<h3><a id="Step_8__Copy_move_or_remove_files_in_HDFS_230"></a><strong>Step 8 : Copy, move or remove files in HDFS</strong></h3>
<ol>
<li>Create a new directory:</li>
</ol>
<pre><code class="language-jason">hdfs dfs –mkdir ${HDFS}learning-labs-move/
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic46.png?raw=true" alt="alt-tag"></p>
<ol start="2">
<li>Copy or move files from one directory to another:</li>
</ol>
<pre><code class="language-jason">hdfs dfs –cp ${HDFS}learning-labs/hadoop-learning-labs.txt  ${HDFS} learning-labs-move/
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic47.png?raw=true" alt="alt-tag"></p>
<p>To view output:</p>
<pre><code class="language-jason">hdfs dfs -ls ${HDFS}learning-labs-move/
</code></pre>
<p>Output of the command is as shown below:<br>
<img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic49.png?raw=true" alt="alt-tag"></p>
<h3><a id="Step_9__Delete_a_file_from_HDFS_255"></a><strong>Step 9 : Delete a file from HDFS</strong></h3>
<pre><code class="language-jason">hdfs dfs –rm ${HDFS}learning-labs-move/hadoop-learning-labs.txt
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic50.png?raw=true" alt="alt-tag"></p>
<p>To view output:</p>
<pre><code class="language-jason">hdfs dfs -ls ${HDFS}learning-labs-move
</code></pre>
<p>Output of the command is as shown below:<br>
<img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic51.png?raw=true" alt="alt-tag"></p>
<h3><a id="Step_10__Explore_other_commands_in_Hadoop_272"></a><strong>Step 10 : Explore other commands in Hadoop</strong></h3>
<p>To explore more commands, use help command as shown below:</p>
<pre><code class="language-jason">hdfs dfs –help
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic52.png?raw=true" alt="alt-tag"></p>
<h2><a id="HOW_TO_USE_APACHE_SPARKSHELL_TO_INTERACT_WITH_SPARK_CLUSTER_282"></a>HOW TO USE APACHE SPARK-SHELL TO INTERACT WITH SPARK CLUSTER</h2>
<h3><a id="Step_1__Echo_command_to_find_HDFS_path_284"></a><strong>Step 1 : Echo command to find HDFS path</strong></h3>
<p>From Hadoop Terminal, use echo command to find the path as shown below:</p>
<pre><code class="language-jason">echo $HDFS
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic29.png?raw=true" alt="alt-tag"></p>
<p>Note: The path obtained needs to be used in commands shown below to replace {$HDFS}.</p>
<h3><a id="Step_2__Launching_Spark_shell_interactive_environemnt_297"></a><strong>Step 2 : Launching Spark shell interactive environemnt</strong></h3>
<p>Spark shell interactive environment needs to be launched from terminal.Please follow the steps given below. User could launch the Spark shell interactive environment either in local mode or in cluster mode but not in both of them.</p>
<p>To launch in Local Mode, please follow the command given below:</p>
<pre><code class="language-jason">spark-shell
</code></pre>
<p>To launch in cluster Mode, please follow the command given below:</p>
<pre><code class="language-jason">spark-shell --master yarn --deploy-mode client
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic53.png?raw=true" alt="alt-tag"></p>
<p>The spark shell prompt is as shown below:</p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic54.png?raw=true" alt="alt-tag"></p>
<h3><a id="Step_3_Word_Count_transformation_program_with_basic_spark_code_319"></a><strong>Step 3: Word Count transformation program with basic spark code</strong></h3>
<p>Execute word count transformation program with basic spark code as follows. The commands mentioned below needs to be executed in sequential order.</p>
<ul>
<li>Load input data from a text file:</li>
</ul>
<pre><code class="language-jason">val inputfile = sc.textFile(&quot;${HDFS}hadoop-learning-labs-people.txt&quot;) 
</code></pre>
<p>Replace the hdfs path with the path obtained with Echo command in Step 1.</p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic25.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Read an input set of text and split the data in to words:</li>
</ul>
<pre><code class="language-jason">val counts = inputfile.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey(_+_);
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic26.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Counts the number of times each word appears and transform it in to word and count.</li>
</ul>
<pre><code class="language-jason">counts.cache()
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic27.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Print the output to terminal.</li>
</ul>
<pre><code class="language-jason">counts.toArray().foreach(println)
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic28.png?raw=true" alt="alt-tag"></p>
<p><strong>Steps Performed Summary:</strong></p>
<ol>
<li>Load input data from a file.</li>
<li>Read an input set of text and split the data in to words.</li>
<li>Counts the number of times each word appears and transform it in to word and count.</li>
<li>Print the output to terminal.</li>
</ol>
<h3><a id="Step_4__Using_SQL_to_do_analytics_in_Spark_shell_365"></a><strong>Step 4 : Using SQL to do analytics in Spark shell</strong></h3>
<p>There are two different ways:</p>
<ol>
<li>Using Spark SQL</li>
<li>Using Normal SQL</li>
</ol>
<p>The commands mentioned below needs to be executed in sequential order.</p>
<p><strong>Using Spark SQL</strong></p>
<ul>
<li>Create an SQL context:</li>
</ul>
<pre><code class="language-jason">val sqlContext = new org.apache.spark.sql.SQLContext(sc)
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic30.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Create a dataframe using the SQL context and data from the file existing in HDFS – “hadoop-learning-labs-people.json”:<br>
(DataFrame is a distributed collection of data organized into named columns. It is conceptually equivalent to a table in a    relational database)</li>
</ul>
<pre><code class="language-jason">val df = sqlContext.jsonFile(&quot;${HDFS}hadoop-learning-labs-people.json &quot;)
</code></pre>
<p>Replace the hdfs path with the path obtained with Echo command in Step 1 OR follow the process below. In order to execute the above mentioned command, user needs to be in spark shell.</p>
<pre><code class="language-jason">exit
</code></pre>
<pre><code class="language-jason">echo $HDFS
</code></pre>
<p>After obtaining the path,</p>
<pre><code class="language-jason">spark-shell
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic31.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Execute command to display the contents of dataframe:</li>
</ul>
<pre><code class="language-jason">df.show()
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic32.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Execute command to select and display the name:</li>
</ul>
<pre><code class="language-jason">df.select(&quot;name&quot;).show()
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic33.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Execute command to select and display the name and age:</li>
</ul>
<pre><code class="language-jason">df.select(df(&quot;name&quot;), df(&quot;age&quot;) + 1).show()
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic34.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Execute command to select and display the name and age with the filter applied as age greater than 21:</li>
</ul>
<pre><code class="language-jason">df.filter(df(&quot;age&quot;) &gt; 21).show()
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic35.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Execute command to select and display the name and age with the filter applied as age greater than 21 and Groupby age with a display of count:</li>
</ul>
<pre><code class="language-jason">df.groupBy(&quot;age&quot;).count().show()
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic36.png?raw=true" alt="alt-tag"></p>
<p><strong>Using Normal SQL</strong></p>
<ul>
<li>Execute commands to fetch the details on console using normal SQL and print the same on console:</li>
</ul>
<pre><code class="language-jason">import sqlContext.implicits._
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic37.png?raw=true" alt="alt-tag"></p>
<pre><code class="language-jason">case class Person(name: String, age: Int)
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic38.png?raw=true" alt="alt-tag"></p>
<pre><code class="language-jason">val people = sc.textFile(&quot;${HDFS}hadoop-learning-labs-people.txt &quot;).map(_.split(&quot;,&quot;)).map(p  =&gt; Person(p(0), p(1).trim.toInt)).toDF()
</code></pre>
<p>Replace the hdfs path with the path obtained with Echo command in Step 1.</p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic39.png?raw=true" alt="alt-tag"></p>
<pre><code class="language-jason">people.registerTempTable(&quot;people&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic40.png?raw=true" alt="alt-tag"></p>
<pre><code class="language-jason">val teenagers = sqlContext.sql(&quot;SELECT name, age FROM people WHERE age &gt;= 13 AND age &lt;= 19&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic41.png?raw=true" alt="alt-tag"></p>
<pre><code class="language-jason">teenagers.map(t =&gt; &quot;Name: &quot; + t(0)).collect().foreach(println)
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic42.png?raw=true" alt="alt-tag"></p>
<p>Steps Performed:</p>
<ol>
<li>Create an SQL context</li>
<li>Create a dataframe using the SQL context and data from the file existing in HDFS – “hadoop-learning-labs-people.json”<br>
(DataFrame is a distributed collection of data organized into named columns. It is conceptually equivalent to a table in a    relational database)</li>
<li>Execute command to display the contents of dataframe.</li>
<li>Execute command to select and display the name and age with the filter applied as age greater than 21 and Groupby age.</li>
<li>Execute command to fetch the details on console using normal SQL and print the same on console.</li>
</ol>
<h2><a id="HOW_TO_USE_HIVE_COMMAND_TO_INTERACT_WITH_HIVE_CLUSTER_497"></a>HOW TO USE HIVE COMMAND TO INTERACT WITH HIVE CLUSTER</h2>
<h3><a id="Step_1__Use_echo_command_to_find_HDFS_path_499"></a><strong>Step 1 : Use echo command to find HDFS path</strong></h3>
<p>From Hadoop Terminal, use echo command to find the path as shown below:</p>
<pre><code class="language-jason">echo $HDFS
</code></pre>
<p>Output of the command is as shown below:<br>
<img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic79.png?raw=true" alt="alt-tag"></p>
<p>Note: The path obtained needs to be used in all the commands shown below to replace {$HDFS}.</p>
<p>The relative path as shown in the screenshot below would be used in Hive. Please make a note of the same:</p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic45.png?raw=true" alt="alt-tag"></p>
<h3><a id="_Step_2__Launch_hive_environment_515"></a>** Step 2 : Launch hive environment**</h3>
<p>Hive interactive environment needs to be launched from terminal.Please follow the steps given below.</p>
<p>To launch hive environment, please follow the command given below:</p>
<pre><code class="language-jason">hive
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic58.png?raw=true" alt="alt-tag"></p>
<p>The prompt would be as shown below:</p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic59.png?raw=true" alt="alt-tag"></p>
<h3><a id="_Step_3__Execute_basic_commands_531"></a>** Step 3 : Execute basic commands**</h3>
<p>Execute some of the basic commands with hive. The commands mentioned below needs to be executed in sequential order.</p>
<ul>
<li>Create a new table.</li>
</ul>
<pre><code class="language-jason">CREATE TABLE people (id INT, name STRING);
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic60.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Show the contents of table created.</li>
</ul>
<pre><code class="language-jason">SHOW TABLES;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic61.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Describe one of the existing table - Students.</li>
</ul>
<pre><code class="language-jason">DESCRIBE students;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic63.png?raw=true" alt="alt-tag"></p>
<ul>
<li>
<p>Alter the created table.</p>
</li>
<li>
<p>Rename table:</p>
</li>
</ul>
<pre><code class="language-jason">ALTER TABLE people RENAME TO people_renamed;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic64.png?raw=true" alt="alt-tag"></p>
<p>To view output:</p>
<pre><code class="language-jason">show tables;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic65.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Add new column for table.</li>
</ul>
<pre><code class="language-jason">ALTER TABLE people_renamed ADD COLUMNS (new_col INT);
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic66.png?raw=true" alt="alt-tag"></p>
<p>To view output:</p>
<pre><code class="language-jason">describe people_renamed;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic67.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Drop Table</li>
</ul>
<pre><code class="language-jason">DROP TABLE people_renamed;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic68.png?raw=true" alt="alt-tag"></p>
<h3><a id="Step_4__Create_Table_from_CSV_file_in_hive_602"></a><strong>Step 4 : Create Table from CSV file in hive</strong></h3>
<p>Learn how to create a table from csv file in hive interactive environment. The commands mentioned below needs to be executed in sequential order.</p>
<ul>
<li>Exit from hive interactive environment and execute the following commands in hdfs terminal. To exit from hive interactive environment, execute the command mentioned below:</li>
</ul>
<pre><code class="language-jason">exit;
</code></pre>
<ul>
<li>Create a new data file directory(students) with hdfs command.</li>
</ul>
<pre><code class="language-jason">hdfs dfs –mkdir ${HDFS}students;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic69.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Copy demo data existing in hadoop(hive_students.csv) to the directory created - students.</li>
</ul>
<pre><code class="language-jason">hdfs dfs –cp ${HDFS}hive_students.csv ${HDFS}students;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic70.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Enter Hive interactive environment and execute the following commands in Hive.</li>
</ul>
<p>To launch Hive environment, please follow the command given below:</p>
<pre><code class="language-jason">hive;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic58.png?raw=true" alt="alt-tag"></p>
<p>The hive prompt is as shown below:</p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic59.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Create an external table in Hive interactive environment.</li>
</ul>
<pre><code class="language-jason">CREATE EXTERNAL TABLE students (id INT, name STRING, birthday STRING) 
    COMMENT 'hive demo table'
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ','
    STORED AS TEXTFILE
location '/user/570c977d4758c1b01983de10/292c1fa0-4c7c-4f91-a03b-a6e1d9246ace/students';
</code></pre>
<p>The path shown in location is the relative path and not the full path. Replace this relative path from Step 1 as shown below:</p>
<p><strong>location</strong>: Relative path obtained from step 1 + students</p>
<p>/user/U58350d4b979c5a583eb43c64/292c1fa0-4c7c-4f91-a03b-a6e1d9246ace/students</p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic71.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Show the definition of table created.</li>
</ul>
<pre><code class="language-jason">DESCRIBE students;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic72.png?raw=true" alt="alt-tag"></p>
<ul>
<li>View the output.</li>
</ul>
<pre><code class="language-jason">Select * from students;
</code></pre>
<p>Output of the command is as shown below:<br>
<img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic73.png?raw=true" alt="alt-tag"></p>
<h3><a id="Step_5__Execute_SQL_commands_from_hive_675"></a><strong>Step 5 : Execute SQL commands from hive</strong></h3>
<p>Learn how to execute some basic sql commands in hive interactive environment. The commands mentioned below needs to be executed in sequential order.</p>
<ul>
<li>Select command.</li>
</ul>
<pre><code class="language-jason">SELECT name FROM students WHERE birthday ='2015-08-20';
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic74.png?raw=true" alt="alt-tag"></p>
<ul>
<li>Insert the results of “Select” command into a new table in Hive.</li>
</ul>
<pre><code class="language-jason">CREATE TABLE students_sub (id INT, name STRING, birthday STRING) ;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic76.png?raw=true" alt="alt-tag"></p>
<pre><code class="language-jason">INSERT OVERWRITE TABLE students_sub SELECT a.* FROM students a where a.birthday &gt; '2015-08-20';
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic77.png?raw=true" alt="alt-tag"></p>
<ul>
<li>View the output:</li>
</ul>
<pre><code class="language-jason">Select * from students_sub ;
</code></pre>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic78.png?raw=true" alt="alt-tag"></p>
<h3><a id="Step_6_Explore_other_commands_in_Hadoop_708"></a><strong>Step 6: Explore other commands in Hadoop</strong></h3>
<p>To explore more commands, exit from hive environment using the command given below.</p>
<pre><code class="language-jason">exit;
</code></pre>
<p>From HDFS, use help command as shown below:</p>
<pre><code class="language-jason">hdfs dfs –help
</code></pre>
<p>Output of the command is as shown below:</p>
<p><img src="https://raw.githubusercontent.com/lpalamth/data-dev-learning-labs/master/labs/HADOOP%20101%20WITH%20BASIC%20TERMINAL%20HANDS-ON%20EXERCISES/assets/images/HadoopBasic52.png?raw=true" alt="alt-tag"></p>
<h2><a id="LESSONS_LEARNT__725"></a>LESSONS LEARNT :</h2>
<ol>
<li>
<p>How to execute basic HDFS commands in Hadoop Terminal.</p>
</li>
<li>
<p>How to use Apache Spark-shell to interact with Spark cluster.</p>
</li>
<li>
<p>How to use Hive command to interact with Hive cluster.</p>
</li>
</ol>
<h1><a id="Congratulations_You_have_successfully_completed_the_Learning_Lab_734"></a><strong>Congratulations! You have successfully completed the Learning Lab!</strong></h1>

</body></html>