# DATA INTEGRATION

<b>Executed on</b>: Hadoop Big Data Platform


## OVERVIEW

This learning lab can be used as a guide to get a high level understanding of Data Integration.</br> 

"Data Integration" refers to combining data from incompatible sources into meaningful and valuable information. 
Please refer the example shown below to get a high level understanding :

![alt-tag](https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/DATA%20INTEGRATION/assets/images/DataIntegration1.jpeg)

We will be using DevNet Data Technology Learning Platform referred as "DTLP" during the course. 

## PRE-REQUISITES

1. Install Chrome Browser.

2. Basic Knowledge of data storage on Hadoop.

## LEARNING OBJECTIVES

1. To get familiarized with the DTLP (Data Technology Learning Platform).
 
2. Understand the basics of Data Integration.

3. Learn how to use different data sources for data integration.

4. Learn how to apply transformation logic to combine and display data from different data sources.


## TERMINOLOGIES USED

### WHAT IS DATA INTEGRATION? - AN INTRODUCTION

"Data Integration" refers to combining data from incompatible sources into meaningful and valuable information.
Please refer the example shown below to get a high level understanding :

![alt-tag](https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/DATA%20INTEGRATION/assets/images/DataIntegration2.jpeg?raw=true)

We are using two different data sources here:</br>
1. Mysql which is a RDBMS data source.</br> 
2. Hive which is a Hadoop data source.</br>

Consider an organization with these two different data sources intends to develop an application or a report. A unified data store is required where data from both the above two data sources can be saved. There should be a unique key or an ID to identify and match the records in each of these data sources.
The unified view thus created helps users to get a better understanding of the data, faster decision making, Operational efficiency, Competitive advantage in the market etc.


### DTLP - AN INTRODUCTION ###

The DevNet Data Technology Learning Platform (DTLP) is an integrated data platform from CISCO that includes an easy-to-use UI, Docker-    based infrastructure, best-in-class open-source big-data components, and Cisco’s APIs and tools for data developers and data  scientists who want to develop, validate and provision their solutions before deploying or to explore, analyze, and    visualize their data. The DTLP environment comes with an inbuilt cloud based IDE (Integrated Development Environment) built    on Hadoop.

For more details, please refer:
https://developer.cisco.com/site/dlp/docs/overview/

## PROCESS OVERVIEW 

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/Process.jpeg?raw=true)

Please follow the steps given below to launch the workspace and execute the lab.

### <b>Step 1 : Login to DTLP</b>

Access the link - https://developer.cisco.com/site/dlp/ and click on the button "Access Now". Please refer the screen shown below:</br>

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/UserAccess1.png?raw=true)

On click of "Access Now" button, you will be navigated to the following page:

<img src="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess2.jpeg?raw=true" data-canonical-src="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess2.jpeg?raw=true" width="400" height="300" />

<b>Existing User?</b>

Click on the button shown below and provide the credentials in login page. Please refer the screen below:

<img src="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess7.jpeg?raw=true" data-canonical-src="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess7.jpeg?raw=true" width="400" height="300" />

On click of button:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess3.jpeg?raw=true)

<b>New User?</b>

Click on “Register Account” button and create a new login profile. Please refer the screen below:

<img src="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess8.jpeg?raw=true" data-canonical-src="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess8.jpeg?raw=true" width="400" height="300" />

On click of "Register Account":

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess5.jpeg?raw=true)


<img src="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess6.jpeg?raw=true" data-canonical-src="https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess6.jpeg?raw=true" width="300" height="400" />

On successful registration, navigate back to the DTLP login page and login with the credentials created:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess3.jpeg?raw=true)


### <b>Step 2 : DTLP Dashboard Page</b>

On login, you will be directed to the DevNet DTLP (Data Technology Learning Platform)dashboard page as shown in the screenshot below:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD COUNT USING SCALA WITH APACHE SPARK/assets/images/UserAccess4.jpeg?raw=true)

### <b>Step 3 : Select Learning lab and Start</b>

From Learning Labs pane, select the learning lab "Data Integration" and click on "Start" button as shown in screenshot below:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/DataIntegration3.jpeg?raw=true)


### <b>Step 4: Workspace Page</b>

On click of Start button, user will be navigated to a workspace page where all the components - Tools and Microservices required to execute the program are available. Please refer the screenshot below:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

### <b>Step 5 : Launch Data Integration Configuration Panel</b>

There are primarily 3 different data transformation operations performed on the data.
1.Join
2.ABS
3.Sort 

<b>Join Operation:</b>

JOIN operation helps to merge data from multiple data sources and extract data based on the common fields. In our use case, the inner join will extract data from mysql and hive databases based on the common field - “ID”. If the ID field matches then the data is extracted and the combined data is displayed in a tabular format.

There are 3 different operations supported within this:

1. Inner Join :
Inner join helps to select records from both the tables(Mysql and Hive tables used as an example here) as long as there is a match between the key fields selected(ID field used in the example shown below) :

Please refer the screenshot below for more details. 

Configure input:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

View output:
![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

2. Full Outer Join :

Full outer join will select all the rows from both the tables(Mysql and Hive tables used as an example here) and displays the combined data in tabular format. It puts NULL in the columns where related records do not exist in the opposite table.

Please refer the screenshot below for more details. 

Configure input:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

View output:
![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

3. Left Join :
Left Join gets all records from the LEFT linked table but if you have selected some columns from the RIGHT table and if there is no related records then those columns will be marked as NULL.

Please refer the screenshot below for more details. 

Configure input:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

View output:
![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)


4. ABS Operation:

ABS stands for Absolute value. ABS function displays any "Integer" field in Absolute format.

Please refer the screenshot below for more details. 

Configure input:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

View output:
![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)


5. Sort Operation:

Sort function is used to display the records of a table selected in sorted order. Sort operation would be working based on a specific field selected. There are sort orders - Ascending and Descending. Based on user’s selected field and sort order type, the output is displayed in tabular format.

Sort - Ascending:

Please refer the screenshot below for more details:

Configure input:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

View output:
![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

Sort - Descending:

Please refer the screenshot below for more details:

Configure input:

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)

View output:
![alt-tag](https://github.com/CiscoDevNet/data-dev-learning-labs/edit/master/labs/DATA%20INTEGRATION/assets/images/NetworkDataIngestion2.png?raw=true)


## LESSONS LEARNT:

1. Basics of Data Integration.

2. How to use different data sources for data integration.

3. How to apply transformation logic to combine and display data from different data sources.

# <center>Congratulations! You have successfully completed the Learning Lab!

