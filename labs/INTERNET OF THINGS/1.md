# **IoT Device Management with DDP**

**Programming Language Used** : Spark

**Executed on** : Hadoop Big Data Platform

**Visualization Tool Used** : Apache Zeppelin

## OVERVIEW

This learning lab can be used as a guide to get a high level understanding of IoT device management on DDP. 
We will be using DevNet Data Development Platform referred as "DDP" during the course. 

## PRE-REQUISITES

1.	Install Chrome Browser.

2.	Basic understanding of Apache Hadoop and Big Data.

3. Basic knowledge of SQL (Structured Query Language).

4. Basic knowledge of Apache Spark.

5. Obtain access to Data Learning Platform -
                                                          Refer: https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/HowToAccessDTLP.md


## LEARNING OBJECTIVES

1. To get familiarized with the DLP (Data Learning Platform).

2. To get familiarized with writing and executing python code in Zeppelin. 

3. To get familiarized with the usage of numpy library for creating a cosine wave.

4. To get familiarized with the usage of matplotlib library to plot data.


## TERMINOLOGIES USED

### APACHE ZEPPELIN - AN INTRODUCTION

Zeppelin is a web-based notebook that enables interactive data analytics. You can make beautiful data-driven, interactive and collaborative documents with SQL, Scala and more. 

Zeppelin enables data engineers, data analysts and data scientists to be more productive by developing, organising, executing, and sharing data code and visualising results without referring to the command line or knowing the cluster details. It brings data exploration, visualization, sharing and collaboration features to Spark. It supports Python and also a growing list of programming languages such as Scala, Hive, SparkSQL, shell and markdown. The various languages are supported via Zeppelin language interpreters. Zeppelin’s notebooks provides interactive snippet-at-time experience to data scientist.

###### Key Features:

1. Web based notebook style editor.

2. Built-in Apache Spark support.

###### Use Cases for Zeppelin :

1. Data Exploration and discovery

2. Data Visualization - Tables,graphs and charts

3. Interactive snippet-at-a-time experience

4. Collaboration and publishing

For more details, please refer : https://zeppelin.apache.org/


### APACHE SPARK - AN INTRODUCTION 

Apache Spark is an open source cluster computing framework. Spark is advertised as “lightning fast cluster computing”. It has a thriving open-source community and is the most active Apache project at the moment. Spark provides an interface for programming entire clusters with implicit data parallelism and fault-tolerance. Apache Spark provides programmers with an application programming interface centered on a data structure called the resilient distributed dataset (RDD), a read-only multiset of data items distributed over a cluster of machines, that is maintained in a fault-tolerant way. 

It was developed in response to limitations in the MapReduce cluster computing paradigm, which forces a particular linear dataflow structure on distributed programs. MapReduce programs read input data from disk, map a function across the data, reduce the results of the map, and store reduction results on disk. Spark provides a faster and more general data processing platform.

###### Key Features

1. Currently provides APIs in Scala, Java, and Python, with support for other languages (such as R) on the way

2. Integrates well with the Hadoop ecosystem and data sources (HDFS, Amazon S3, Hive, HBase, Cassandra, etc.)

3. Can run on clusters managed by Hadoop YARN or Apache Mesos, and can also run standalone

###### How to Use Apache Spark? 

###### Example : Using spark to detect an earthquake by analyzing the twitter stream

1. Using Spark streaming, filter tweets that seem relevant like “earthquake” or “shaking”. 

2. Run semantic analysis on the tweets to determine if they appear to be referencing a current earthquake occurrence. Tweets like ”Earthquake!” or ”Now it is shaking”, for example, would be considered positive matches, whereas tweets like “Attending an Earthquake Conference” or ”The earthquake yesterday was scary” would not. 

3. Using the streaming technique, we could detect the  positive tweets in a defined time window and thereby can be used to send alert messages.

For more details, please refer:
http://spark.apache.org/
https://en.wikipedia.org/wiki/Apache_Spark


## PROCESS OVERVIEW 

![alt-tag](https://raw.githubusercontent.com/CiscoDevNet/data-dev-learning-labs/master/labs/WORD%20COUNT%20USING%20SCALA%20WITH%20APACHE%20SPARK/assets/images/Process31.jpeg?raw=true)

Please follow the steps given below to launch the workspace and execute the lab.

### **Step 1 : Select pre-configured workspace from DDP**

After launching the DDP dashboard page, navigate to workspace tab. Select the pre-configured workspace "IoT Demo" and click on "Open" button as shown in screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/BASIC%20DATA%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/images/ZeppelinVisualization10.jpeg?raw=true)

### **Step 2 : Workspace Page**

On click of Open button, user will be navigated to the workspace page where all the components - IDE, Tools and Microservices required to execute the program are available. Please refer the screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/BASIC%20DATA%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/images/ZeppelinVisualization.jpeg?raw=true)

### **Step 3 : Start Services in Workspace**


* Start the services. Please refer screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/BASIC%20DATA%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/images/ZeppelinVisualization1.jpeg?raw=true)

* Once started, the colour of the icon changes to green and launch button is enabled.

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/BASIC%20DATA%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/images/ZeppelinVisualization2.jpeg?raw=true)

* If the task is in stopped status then click on it to start again. 

### **Step 4 : Launch IoTDemoWeb**


Click on launch button and user will be navigated to new tab where real time streaming of data collected by sensors is shown.

The following data is collected:

1. Humidity
2. Particle
3. Noise
4. Temperature







### **Step 5 : Launch Zeppelin**

Click on launch button and user will be navigated to Zeppelin home page.

Points to note:

(The pop-up may be blocked in browser configuration. Click on the red pop up blocker icon and select **Always allow pop-up from http://xxx.xxx.xxx.xxx ** and click on **Done** button.)  

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/popUpBlockerAllowed1.jpeg?raw=true)

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/DATA%20EXPLORATION%2C%20ANALYSIS%20AND%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/popUpBlockerAllowed2.jpeg?raw=true)

On enabling the pop-up, Zeppelin would open in a new window taking the user to Zeppelin home page as shown in screenshot below.

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/BASIC%20DATA%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/images/ZeppelinVisualization12.jpeg?raw=true)


### **Step 5 : Select Zeppelin notebook**

* Select pre-created notebook - "IoT-Spark-Mongo-Example" from home page as shown in screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/BASIC%20DATA%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/images/ZeppelinVisualization4.jpeg?raw=true)

* The Zeppelin interactive,development and visualisation environment is now ready for use. The pre-created notebook has all the codes required for executing this. Each of the code shown below needs to be executed sequentially. 

### **Step 6 : Execute Python Code**

We are using code written in Python for data generation. 

The code is as follows:


On successful execution of code, you can view the cosine signal data in Zeppelin as shown in screenshot below:

![Figure](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/BASIC%20DATA%20VISUALIZATION%20USING%20APACHE%20ZEPPELIN/assets/images/ZeppelinVisualization8.jpeg?raw=true)


## LESSONS LEARNT

1. How to write and execute Spark code in Zeppelin.






# **Congratulations! You have successfully completed the Learning Lab!**
